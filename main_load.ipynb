{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathAll(object):\n",
    "    # 停用词\n",
    "    stopWordList = \"./stopwords/hit_stopwords.txt\"\n",
    "    # 词向量路径\n",
    "    word2vec=\"./word2vec/sgns.weibo.bigram-char/sgns.weibo.bigram-char\"\n",
    "    # 模型路径\n",
    "    model_load=\"./model_load/ABiLSTM_Att.weibo300.wuhan_labeled_plus.2/AdLSTM_Att_epoch_2\"\n",
    "\n",
    "    # 待预测文本\n",
    "    dataSource = \"./data/2class/reviews_wuhan_tencent_small.csv\"\n",
    "    # 预测结果的保存路径\n",
    "    result_save=\"./data/result/result_wuhan_tencent_2class_ABiLSTM_Att_weibo300_labeled_plus_2.csv\"\n",
    "\n",
    "# 词向量的维数\n",
    "Embedding_size=300\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5468/1311644174.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m##实例化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mseqLen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseqLength\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPathAll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataSource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPathAll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopWordList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msequenceLen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseqLen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sequence length:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msequenceLen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\2022大三下\\智慧城市与大数据分析\\ABiLSTM_Att\\tools.py\u001b[0m in \u001b[0;36mseq_len\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mreview\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"reviewtext\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreview\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#每次读一行\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0mline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_re\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m             \u001b[1;31m#结巴分词\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mcut_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjieba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlcut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\envs\\tensorflow\\lib\\re.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "from tools import seqLength\n",
    "##实例化\n",
    "seqLen=seqLength(PathAll.dataSource,PathAll.stopWordList)\n",
    "sequenceLen=seqLen.seq_len()\n",
    "\n",
    "print(\"sequence length:\",sequenceLen)\n",
    "seqLen.plot_seqence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config\n",
    "# 实例化配置参数对象\n",
    "config = Config(sequenceLen,Embedding_size)\n",
    "config.rate = 0 #设置所有的语料都是测试集\n",
    "config.model.dropoutKeepProb = 1.0 #全都保留下来\n",
    "config.sequenceLength=87\n",
    "\n",
    "# 读取数据集对象到内存中\n",
    "import dataSet\n",
    "data = dataSet.Dataset(config,PathAll)\n",
    "data.dataGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (0, 87)\n",
      "train label shape: (0,)\n",
      "test data shape: (74194, 87)\n",
      "test label shape: (74194, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"train data shape: {}\".format(data.trainReviews.shape))\n",
    "print(\"train label shape: {}\".format(data.trainLabels.shape))\n",
    "print(\"test data shape: {}\".format(data.testReviews.shape))\n",
    "print(\"test label shape: {}\".format(data.testLabels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ABiLSTM_Attention_2class\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_load/ABiLSTM_Att.weibo300.wuhan_labeled_plus.2/AdLSTM_Att_epoch_2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "predictions=[]\n",
    "binaryPreds=[]\n",
    "\n",
    "# 定义计算图\n",
    "with tf.Graph().as_default():\n",
    "    # 定义会话\n",
    "    with tf.Session() as sess:\n",
    "        lstm = ABiLSTM_Attention_2class(config, data.wordEmbedding, data.indexFreqs)\n",
    "        tf.train.Saver().restore(sess, PathAll.model_load)\n",
    "            \n",
    "        feed_dict = {\n",
    "            lstm.inputX: data.testReviews,\n",
    "            lstm.inputY: data.testLabels,\n",
    "            lstm.dropoutKeepProb:config.model.dropoutKeepProb\n",
    "        }\n",
    "        predictions, binaryPreds = sess.run(\n",
    "            [lstm.predictions, lstm.binaryPreds],\n",
    "            feed_dict)\n",
    "\n",
    "        accuracy = accuracy_score(data.testLabels, binaryPreds)\n",
    "        precision = precision_score(data.testLabels, binaryPreds, average='macro')\n",
    "        recall = recall_score(data.testLabels, binaryPreds, average='macro')\n",
    "        F = 2 * (precision * recall) / (precision + recall)\n",
    "        print(\"acc: {}, recall: {}, F1:{}\".format(accuracy,recall, F))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "reviews = data.test_ReviewsText.tolist()\n",
    "pre_sentiment = predictions\n",
    "pre_class = binaryPreds\n",
    "true_class = data.testLabels\n",
    "correct_prediction = tf.cast(tf.equal(pre_class, true_class), tf.float32).numpy()\n",
    "df1 = pd.DataFrame()\n",
    "df1[\"reviewId\"] = data._reviewId[int(len(data._reviewId)*data._rate):]\n",
    "df1[\"reviews\"] = reviews\n",
    "df1[\"predictions\"] = pre_sentiment\n",
    "df1[\"pre_class\"] = binaryPreds\n",
    "df1[\"true_class\"] = true_class\n",
    "df1[\"accuracy\"] = correct_prediction\n",
    "df1.to_csv(PathAll.result_save, encoding=\"utf_8_sig\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e14dff31657d72d8f438edb53d1760a8d6796be921cd9f1003fb34023c1344f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
